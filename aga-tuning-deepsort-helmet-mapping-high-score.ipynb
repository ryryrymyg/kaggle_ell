{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Helmet Mapping + Deepsort\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# Install helmet-assignment helper code\n!pip install ../input/helmet-assignment-helpers/helmet-assignment-main/ > /dev/null 2>&1\nfrom helmet_assignment.score import NFLAssignmentScorer, check_submission\nfrom helmet_assignment.features import add_track_features","metadata":{"execution":{"iopub.status.busy":"2021-10-29T19:52:08.23242Z","iopub.execute_input":"2021-10-29T19:52:08.232737Z","iopub.status.idle":"2021-10-29T19:52:37.652429Z","shell.execute_reply.started":"2021-10-29T19:52:08.232706Z","shell.execute_reply":"2021-10-29T19:52:37.651546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Baseline helmet mapping\nThis section uses the simple helmet mapping approach from the awesome notebook:\n\nhttps://www.kaggle.com/its7171/nfl-baseline-simple-helmet-mapping","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport itertools\nimport glob\nimport os\nimport cv2\nfrom sklearn.metrics import accuracy_score\nfrom tqdm.auto import tqdm\nfrom multiprocessing import Pool\nfrom matplotlib import pyplot as plt\nfrom sklearn.cluster import KMeans\nimport random\nimport pandas_profiling","metadata":{"execution":{"iopub.status.busy":"2021-10-29T19:52:56.815385Z","iopub.execute_input":"2021-10-29T19:52:56.815748Z","iopub.status.idle":"2021-10-29T19:52:58.225405Z","shell.execute_reply.started":"2021-10-29T19:52:56.815706Z","shell.execute_reply":"2021-10-29T19:52:58.224475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Settings and loading data\n\nNote I've extracted `max_iter`, `DIG_STEP` and `DIG_MAX` to the top for easy experimentation. I've also modified the code to run in debug mode if running on the public test set.","metadata":{}},{"cell_type":"code","source":"n_test_videos = len(os.listdir('../input/nfl-health-and-safety-helmet-assignment/test/'))\n# Run in debug mode unless during submission\nif n_test_videos == 6:\n    debug = True\nelse:\n    debug = False\n\n# Configurables\nn_debug_samples = 4\nrandom_state = 42\nCONF_THRE = 0.4 #使うbbox確度\nmax_iter = 1000\nDIG_STEP = 3\nDIG_MAX = DIG_STEP*10\n\n# Read in the data.\n\nBASE_DIR = '../input/nfl-health-and-safety-helmet-assignment'\n\nlabels = pd.read_csv(f'{BASE_DIR}/train_labels.csv')\nif debug:\n    tracking = pd.read_csv(f'{BASE_DIR}/train_player_tracking.csv')\n    helmets = pd.read_csv(f'{BASE_DIR}/train_baseline_helmets.csv')\nelse:\n    tracking = pd.read_csv(f'{BASE_DIR}/test_player_tracking.csv')\n    helmets = pd.read_csv(f'{BASE_DIR}/test_baseline_helmets.csv')\n    \ntracking = add_track_features(tracking)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T21:34:31.046393Z","iopub.execute_input":"2021-10-29T21:34:31.046875Z","iopub.status.idle":"2021-10-29T21:34:35.026653Z","shell.execute_reply.started":"2021-10-29T21:34:31.046831Z","shell.execute_reply":"2021-10-29T21:34:35.0258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_cols(df):\n    df['game_play'] = df['video_frame'].str.split('_').str[:2].str.join('_')\n    if 'video' not in df.columns:\n        df['video'] = df['video_frame'].str.split('_').str[:3].str.join('_') + '.mp4'\n    return df\n\nif debug:\n    helmets = add_cols(helmets)\n    labels = add_cols(labels)\n    # Select `n_debug_samples` worth of videos to debug with\n#     sample_videos = labels['video'].drop_duplicates() \\\n#         .sample(n_debug_samples, random_state=random_state).tolist()\n    sample_videos = labels['video'].drop_duplicates() \\\n        .head(n_debug_samples).tolist()\n    sample_gameplays = ['_'.join(x.split('_')[:2]) for x in sample_videos]\n    tracking = tracking[tracking['game_play'].isin(sample_gameplays)]\n    helmets = helmets[helmets['video'].isin(sample_videos)]\n    labels = labels[labels['video'].isin(sample_videos)]\ntracking.shape, helmets.shape, labels.shape","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-29T21:34:36.943913Z","iopub.execute_input":"2021-10-29T21:34:36.944337Z","iopub.status.idle":"2021-10-29T21:34:49.692808Z","shell.execute_reply.started":"2021-10-29T21:34:36.9443Z","shell.execute_reply":"2021-10-29T21:34:49.691829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sample_videos)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T21:34:59.36555Z","iopub.execute_input":"2021-10-29T21:34:59.365964Z","iopub.status.idle":"2021-10-29T21:34:59.371398Z","shell.execute_reply.started":"2021-10-29T21:34:59.365924Z","shell.execute_reply":"2021-10-29T21:34:59.369605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_nearest(array, value):\n    value = int(value)\n    array = np.asarray(array).astype(int)\n    idx = (np.abs(array - value)).argmin()\n    return array[idx]\n\ndef norm_arr(a):\n    a = a-a.min()\n    a = a/a.max()\n    return a\n    \ndef dist(a1, a2):\n    return np.linalg.norm(a1-a2)\n\ndef dist_for_different_len(a1, a2):\n    assert len(a1) >= len(a2), f'{len(a1)}, {len(a2)}'\n    len_diff = len(a1) - len(a2)\n    a2 = norm_arr(a2)\n    if len_diff == 0:\n        a1 = norm_arr(a1)\n        return dist(a1,a2), ()\n    else:\n        min_dist = 10000\n        min_detete_idx = None\n        cnt = 0\n        del_list = list(itertools.combinations(range(len(a1)),len_diff))\n        if len(del_list) > max_iter:\n            del_list = random.sample(del_list, max_iter)\n        for detete_idx in del_list:\n            this_a1 = np.delete(a1, detete_idx)\n            this_a1 = norm_arr(this_a1)\n            this_dist = dist(this_a1, a2)\n            #print(len(a1), len(a2), this_dist)\n            if min_dist > this_dist:\n                min_dist = this_dist\n                min_detete_idx = detete_idx\n                \n        return min_dist, min_detete_idx\n        \ndef rotate_arr(u, t, deg=True):\n    if deg == True:\n        t = np.deg2rad(t)\n    R = np.array([[np.cos(t), -np.sin(t)],\n                  [np.sin(t),  np.cos(t)]])\n    return  np.dot(R, u)\n\ndef dist_rot(tracking_df, a2):\n    tracking_df = tracking_df.sort_values('x')\n    x = tracking_df['x']\n    y = tracking_df['y']\n    min_dist = 10000\n    min_idx = None\n    min_x = None\n    for dig in range(-DIG_MAX,DIG_MAX+1,DIG_STEP):\n        arr = rotate_arr(np.array((x,y)), dig)\n        this_dist, this_idx = dist_for_different_len(np.sort(arr[0]), a2)\n        if min_dist > this_dist:\n            min_dist = this_dist\n            min_idx = this_idx\n            min_x = arr[0]\n    tracking_df['x_rot'] = min_x\n    player_arr = tracking_df.sort_values('x_rot')['player'].values\n    players = np.delete(player_arr,min_idx)\n    return min_dist, players\n\n\ndef mapping_df(args):\n    video_frame, df = args\n    gameKey,playID,view,frame = video_frame.split('_')\n    gameKey = int(gameKey)\n    playID = int(playID)\n    frame = int(frame)\n    this_tracking = tracking[(tracking['gameKey']==gameKey) & (tracking['playID']==playID)]\n    est_frame = find_nearest(this_tracking.est_frame.values, frame)\n    this_tracking = this_tracking[this_tracking['est_frame']==est_frame]\n    len_this_tracking = len(this_tracking)\n    df['center_h_p'] = (df['left']+df['width']/2).astype(int)\n    df['center_h_m'] = (df['left']+df['width']/2).astype(int)*-1\n    df = df[df['conf']>CONF_THRE].copy()\n    if len(df) > len_this_tracking:\n        df = df.tail(len_this_tracking)\n    df_p = df.sort_values('center_h_p').copy()\n    df_m = df.sort_values('center_h_m').copy()\n    \n    if view == 'Endzone':\n        this_tracking['x'], this_tracking['y'] = this_tracking['y'].copy(), this_tracking['x'].copy()\n    a2_p = df_p['center_h_p'].values\n    a2_m = df_m['center_h_m'].values\n\n    min_dist_p, min_detete_idx_p = dist_rot(this_tracking ,a2_p)\n    min_dist_m, min_detete_idx_m = dist_rot(this_tracking ,a2_m)\n    if min_dist_p < min_dist_m:\n        min_dist = min_dist_p\n        min_detete_idx = min_detete_idx_p\n        tgt_df = df_p\n    else:\n        min_dist = min_dist_m\n        min_detete_idx = min_detete_idx_m\n        tgt_df = df_m\n    #print(video_frame, len(this_tracking), len(df), len(df[df['conf']>CONF_THRE]), this_tracking['x'].mean(), min_dist_p, min_dist_m, min_dist)\n    tgt_df['label'] = min_detete_idx\n    return tgt_df[['video_frame','left','width','top','height','label']]\n\np = Pool(processes=4)\nsubmission_df_list = []\ndf_list = list(helmets.groupby('video_frame'))\nwith tqdm(total=len(df_list)) as pbar:\n    for this_df in p.imap(mapping_df, df_list):\n        submission_df_list.append(this_df)\n        pbar.update(1)\np.close()\n\nsubmission_df = pd.concat(submission_df_list)\nsubmission_df.to_csv('submission-baseline.csv', index=False)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-29T21:36:14.995187Z","iopub.execute_input":"2021-10-29T21:36:14.995573Z","iopub.status.idle":"2021-10-29T22:26:31.650847Z","shell.execute_reply.started":"2021-10-29T21:36:14.99554Z","shell.execute_reply":"2021-10-29T22:26:31.649842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.profile_report()","metadata":{"execution":{"iopub.status.busy":"2021-10-21T13:41:14.38812Z","iopub.execute_input":"2021-10-21T13:41:14.38845Z","iopub.status.idle":"2021-10-21T13:41:14.453888Z","shell.execute_reply.started":"2021-10-21T13:41:14.388369Z","shell.execute_reply":"2021-10-21T13:41:14.452559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Score the predictions before applying deepsort postprocessing\n\nThe scores are roughly ~0.3, which is similar to the public leaderboard.","metadata":{}},{"cell_type":"code","source":"if debug:\n    scorer = NFLAssignmentScorer(labels)\n    baseline_score = scorer.score(submission_df)\n    print(f\"validation score {baseline_score:0.4f}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-29T22:46:15.335522Z","iopub.execute_input":"2021-10-29T22:46:15.335952Z","iopub.status.idle":"2021-10-29T22:46:16.576394Z","shell.execute_reply.started":"2021-10-29T22:46:15.335874Z","shell.execute_reply":"2021-10-29T22:46:16.575466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Deepsort Postprocessing\n\nDeepsort is a popular framework for object tracking within video. \n- [This blog post](https://nanonets.com/blog/object-tracking-deepsort/\n) shows some examples of it being put to use.\n- This notebook shows how to apply deepsort to this helmet dataset: https://www.kaggle.com/s903124/nfl-helmet-with-yolov5-deepsort-starter\n- You can also read the paper for deepsort here: https://arxiv.org/pdf/1703.07402.pdf\n\nThe approach is fairly simple:\n1. Step through each frame in a video and apply the deepsort algorithm. This clusters helmets across frames when it is the same player/helmet.\n2. Group by each of these deepsort clusters - and pick the most common label for that cluster. Then override all of the predictions for that helmet to the same player.","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/easydict-master/easydict-master/')\n# https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch\nsys.path.append('../input/yolov5-deepsort-pytorch/Yolov5_DeepSort_Pytorch-master/Yolov5_DeepSort_Pytorch-master/deep_sort_pytorch/')\nfrom deep_sort.deep_sort import DeepSort\nfrom utils.parser import get_config","metadata":{"execution":{"iopub.status.busy":"2021-10-29T22:46:25.910371Z","iopub.execute_input":"2021-10-29T22:46:25.910688Z","iopub.status.idle":"2021-10-29T22:46:25.916054Z","shell.execute_reply.started":"2021-10-29T22:46:25.910658Z","shell.execute_reply":"2021-10-29T22:46:25.915023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Deepsort config\n\nDeepsort uses a config yaml file for some settings. These are just the default configs and could be improved.","metadata":{}},{"cell_type":"markdown","source":"yamlは#がコメントじゃないっぽいので注意\n","metadata":{}},{"cell_type":"code","source":"%%writefile deepsort.yaml\n\nDEEPSORT:\n  REID_CKPT: \"../input/yolov5-deepsort-pytorch/ckpt.t7\"\n  MAX_DIST: 0.2\n  MIN_CONFIDENCE: 0.3\n  NMS_MAX_OVERLAP: 0.5\n  MAX_IOU_DISTANCE: 0.9\n  MAX_AGE: 15\n  N_INIT: 1\n  NN_BUDGET: 100","metadata":{"execution":{"iopub.status.busy":"2021-10-29T22:46:28.120254Z","iopub.execute_input":"2021-10-29T22:46:28.120569Z","iopub.status.idle":"2021-10-29T22:46:28.126054Z","shell.execute_reply.started":"2021-10-29T22:46:28.120539Z","shell.execute_reply":"2021-10-29T22:46:28.125198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nHelper functions from yolov5 to plot deepsort labels.\n\"\"\"\n\ndef compute_color_for_id(label):\n    \"\"\"\n    Simple function that adds fixed color depending on the id\n    \"\"\"\n    palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)\n\n    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n    return tuple(color)\n\ndef plot_one_box(x, im, color=None, label=None, line_thickness=3):\n    # Plots one bounding box on image 'im' using OpenCV\n    assert im.data.contiguous, 'Image not contiguous. Apply np.ascontiguousarray(im) to plot_on_box() input image.'\n    tl = line_thickness or round(0.002 * (im.shape[0] + im.shape[1]) / 2) + 1  # line/font thickness\n    color = color or [random.randint(0, 255) for _ in range(3)]\n    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n    cv2.rectangle(im, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n    if label: \n        tf = max(tl - 1, 1)  # font thickness\n        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n        cv2.rectangle(im, c1, c2, color, -1, cv2.LINE_AA)  # filled\n        cv2.putText(im, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n    return im","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-29T22:46:32.275409Z","iopub.execute_input":"2021-10-29T22:46:32.275729Z","iopub.status.idle":"2021-10-29T22:46:32.285957Z","shell.execute_reply.started":"2021-10-29T22:46:32.275701Z","shell.execute_reply":"2021-10-29T22:46:32.284919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Functions to apply deepsort to helmet boxes.\n\nBelow are two functions `deepsort_helmets` which runs deepsort across a video. There is a lot of room for improving this function. The merging of deepsort labels onto the original helmet boxes is currently done in a very crude manner.\n\n`add_deepsort_label_col` mapps the most common label to each deepsort cluster.","metadata":{}},{"cell_type":"code","source":"def deepsort_helmets(video_data,\n                     video_dir,\n                     deepsort_config='deepsort.yaml',\n                     plot=False,\n                     plot_frames=[]):\n    \n    # Setup Deepsort\n    cfg = get_config()\n    cfg.merge_from_file(deepsort_config)    \n    deepsort = DeepSort(cfg.DEEPSORT.REID_CKPT,\n                        max_dist=cfg.DEEPSORT.MAX_DIST,\n                        min_confidence=cfg.DEEPSORT.MIN_CONFIDENCE,\n                        nms_max_overlap=cfg.DEEPSORT.NMS_MAX_OVERLAP,\n                        max_iou_distance=cfg.DEEPSORT.MAX_IOU_DISTANCE,\n                        max_age=cfg.DEEPSORT.MAX_AGE,\n                        n_init=cfg.DEEPSORT.N_INIT,\n                        nn_budget=cfg.DEEPSORT.NN_BUDGET,\n                        use_cuda=True)\n    \n    # Run through frames.\n    video_data = video_data.sort_values('frame').reset_index(drop=True)\n    ds = []\n    d_baseline = []\n    d_preds = []\n    \n    for frame, d in tqdm(video_data.groupby(['frame']), total=video_data['frame'].nunique()):\n        d['x'] = (d['left'] + round(d['width'] / 2))\n        d['y'] = (d['top'] + round(d['height'] / 2))\n\n        xywhs = d[['x','y','width','height']].values\n\n        cap = cv2.VideoCapture(f'{video_dir}/{myvideo}.mp4')\n        cap.set(cv2.CAP_PROP_POS_FRAMES, frame-1) # optional\n        success, image = cap.read()\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        confs = np.ones([len(d),])\n        clss =  np.zeros([len(d),])\n        outputs = deepsort.update(xywhs, confs, clss, image)\n\n        if (plot and frame > cfg.DEEPSORT.N_INIT) or (frame in plot_frames):\n            for j, (output, conf) in enumerate(zip(outputs, confs)): \n\n                bboxes = output[0:4]\n                id = output[4]\n                cls = output[5]\n\n                c = int(cls)  # integer class\n                label = f'{id}'\n                color = compute_color_for_id(id)\n                im = plot_one_box(bboxes, image, label=label, color=color, line_thickness=2)\n            fig, ax = plt.subplots(figsize=(15, 10))\n            video_frame = d['video_frame'].values[0]\n            ax.set_title(f'Deepsort labels: {video_frame}')\n            plt.imshow(im)\n            plt.show()\n\n        preds_df = pd.DataFrame(outputs, columns=['left','top','right','bottom','deepsort_cluster','class'])\n#         d_preds.append(preds_df)\n#         d_baseline.append(d)\n        \n        if len(preds_df) > 0:\n            # TODO Fix this messy merge\n            d = pd.merge_asof(d.sort_values(['left','top']),\n                              preds_df[['left','top','deepsort_cluster']] \\\n                              .sort_values(['left','top']), on='left', suffixes=('','_deepsort'),\n                              direction='nearest')\n            \n#             d = pd.merge_asof(preds_df[['left','top','deepsort_cluster']].sort_values(['left','top']),\n#                               d.sort_values(['left','top']), on='left', suffixes=('','_deepsort'),\n#                               direction='nearest')\n        ds.append(d)\n        \n    dout = pd.concat(ds)\n    \n#     #debug team-------------\n#     dout_preds = pd.concat(d_preds)\n#     dout_baseline = pd.concat(d_baseline)\n#     dout_preds.to_csv(\"dout_preds.csv\")\n#     dout_baseline.to_csv(\"dout_baseline.csv\")\n    #-----------------------\n    \n    return dout\n\ndef add_deepsort_label_col(out):\n    # Find the top occuring label for each deepsort_cluster\n    sortlabel_map = out.groupby('deepsort_cluster')['label'].value_counts() \\\n        .sort_values(ascending=False).to_frame() \\\n        .rename(columns={'label':'label_count'}) \\\n        .reset_index() \\\n        .groupby(['deepsort_cluster']) \\\n        .first()['label'].to_dict()\n    # Find the # of times that label appears for the deepsort_cluster.\n    sortlabelcount_map = out.groupby('deepsort_cluster')['label'].value_counts() \\\n        .sort_values(ascending=False).to_frame() \\\n        .rename(columns={'label':'label_count'}) \\\n        .reset_index() \\\n        .groupby(['deepsort_cluster']) \\\n        .first()['label_count'].to_dict()\n    \n    out['label_deepsort'] = out['deepsort_cluster'].map(sortlabel_map)\n    out['label_count_deepsort'] = out['deepsort_cluster'].map(sortlabelcount_map)\n\n    return out\n\ndef score_vs_deepsort(myvideo, out, labels):\n    # Score the base predictions compared to the deepsort postprocessed predictions.\n    myvideo_mp4 = myvideo + '.mp4'\n    labels_video = labels.query('video == @myvideo_mp4')\n    scorer = NFLAssignmentScorer(labels_video)\n    out_deduped = out.groupby(['video_frame','label']).first().reset_index()\n    base_video_score = scorer.score(out_deduped)\n    \n    out_preds = out.drop('label', axis=1).rename(columns={'label_deepsort':'label'})\n    print(out_preds.shape)\n    out_preds = out_preds.groupby(['video_frame','label']).first().reset_index()\n    print(out_preds.shape)\n    deepsort_video_score = scorer.score(out_preds)\n    print(f'{base_video_score:0.5f} before --> {deepsort_video_score:0.5f} deepsort')","metadata":{"execution":{"iopub.status.busy":"2021-10-29T22:46:34.460393Z","iopub.execute_input":"2021-10-29T22:46:34.460747Z","iopub.status.idle":"2021-10-29T22:46:34.48275Z","shell.execute_reply.started":"2021-10-29T22:46:34.460716Z","shell.execute_reply":"2021-10-29T22:46:34.48163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"新規bboxと死んだbboxを座標近いやつ紐づけ\n汚い実装すみません","metadata":{}},{"cell_type":"code","source":"def connect_bboxies(df):\n    out_df = df.copy()\n    out = []\n    \n    #各videoごとに処理\n    for video in df['video'].drop_duplicates().values:\n        df_v = df[df[\"video\"] == video].copy()\n        \n        a = []\n        pv_clusters = set(a) \n        c_clusters = set(a)\n        \n        #置換リスト [new, death]\n        replace_list = []\n        \n        #既知のdeepクラスタ\n        known_cluster = {}\n        \n        #死者\n        death_dict = {} #bbox id key item\n        death_frame = pd.DataFrame()\n        \n        # frame\n        # idxにはframeの値がintで入っている groupbyのkey\n        for idx, frame in df_v.groupby('frame'):\n            cl = frame[\"deepsort_cluster\"].fillna(-1).values\n            \n            #1フレーム目はdeepsortclusterが無いので除外\n            if idx <= 2:\n                # print(frame)\n                pv_clusters = set(cl)\n                # print(pv_clusters)\n                continue\n            \n            # death 新しく出てきたやつ検知\n            death = pv_clusters - set(cl)\n            new = set(cl)-pv_clusters\n            \n            #新規勢が来た場合\n            #同じフレームでのdeathに反応するかもなので、newから処理する\n            if new:\n                # print(\"new {}\".format(new))\n                for n in new:\n                    # 既知のものがもう一回出てるだけか？\n                    if n in known_cluster.keys():\n                        xx=0\n                        if n in death_dict.keys():\n                            death_dict.pop(n)\n                        \n                    else:\n                        xx = 0\n                        for d in death_dict.keys():\n                            new_item = frame[frame[\"deepsort_cluster\"] == n]\n                            death_item = death_dict[d]\n                            \n                            # えーい全部べた書きだ ワハハ\n                            death_left = death_item[\"left\"].values[0]\n                            death_top = death_item[\"top_deepsort\"].values[0]\n                            \n                            new_left = new_item[\"left\"].values[0]\n                            new_top = new_item[\"top_deepsort\"].values[0]\n                            \n                            left_d = death_left - new_left\n                            top_d = death_top - new_top\n                            \n                            # 消滅後と新規bboxが相応に近かったら紐づけ\n                            # パラメータ\n                            dist_th = 50\n                            \n                            if (-dist_th <= left_d <= dist_th) and (-dist_th <= top_d <= dist_th):\n                                replace_list.append([n,d])\n                                death_dict.pop(d)\n                                break\n                     \n                        \n            # 死者が出た場合 一戸まえのframeから座標情報とる\n            if death:\n                for d in death:\n                    death_dict[d] = known_cluster[d]\n  \n            # pv_clusterの更新\n            pv_clusters = set(cl)\n            \n            # 基地クラスタの更新\n            for c in cl:\n                known_cluster[c] = frame[frame[\"deepsort_cluster\"] == c]\n            # print(known_cluster.keys())\n            \n        # print(replace_list)\n        for re in reversed(replace_list):\n            df_v = df_v.replace({'deepsort_cluster': {re[0]: re[1]}})\n\n        out.append(df_v)\n        print(replace_list)\n\n        \n    out = pd.concat(out)\n    print(\"tuned.\")\n    return out","metadata":{"execution":{"iopub.status.busy":"2021-10-29T22:46:52.970563Z","iopub.execute_input":"2021-10-29T22:46:52.970903Z","iopub.status.idle":"2021-10-29T22:46:52.985027Z","shell.execute_reply.started":"2021-10-29T22:46:52.970857Z","shell.execute_reply":"2021-10-29T22:46:52.984232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Apply Deepsort to Baseline Predictions","metadata":{}},{"cell_type":"code","source":"# Add video and frame columns to submission.\nsubmission_df['video'] = submission_df['video_frame'].str.split('_').str[:3].str.join('_')\nsubmission_df['frame'] = submission_df['video_frame'].str.split('_').str[-1].astype('int')\n\nif debug:\n    video_dir = '../input/nfl-health-and-safety-helmet-assignment/train/'\nelse:\n    video_dir = '../input/nfl-health-and-safety-helmet-assignment/test/'\n\n# Loop through test videos and apply. If in debug mode show the score change.\nout_ds = []\nouts = []\n# r = list(range(100,161,1))\nr = [10,100,200]\nfor myvideo, video_data in tqdm(submission_df.groupby('video'), total=submission_df['video'].nunique()):\n    print(f'==== {myvideo} ====')\n    if debug:\n        # Plot deepsort labels when in debug mode.\n        out = deepsort_helmets(video_data, video_dir, plot_frames=r)\n    else:\n        out = deepsort_helmets(video_data, video_dir)\n    out_ds.append(out)\n    \n    #ここに補正用関数入れる\n    if \"Sideline\" in myvideo:\n        print(myvideo)\n        out = connect_bboxies(out)\n    \n    out = add_deepsort_label_col(out)\n    outs.append(out)\n    if debug:\n        # Score\n        score_vs_deepsort(myvideo, out, labels)\nsubmission_deepsort = pd.concat(outs).copy()","metadata":{"execution":{"iopub.status.busy":"2021-10-29T23:26:18.444783Z","iopub.execute_input":"2021-10-29T23:26:18.44516Z","iopub.status.idle":"2021-10-29T23:51:02.06528Z","shell.execute_reply.started":"2021-10-29T23:26:18.445129Z","shell.execute_reply":"2021-10-29T23:51:02.064207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"デバッグ用","metadata":{}},{"cell_type":"code","source":"# deepsort_out = pd.concat(out_ds).copy()\n# print(out_ds)\n# print(out_ds[0])\n# x = pd.DataFrame(out_ds)\n# out_ds.head()\n\n# deepsort_out.profile_report()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T16:45:19.450418Z","iopub.execute_input":"2021-10-23T16:45:19.450789Z","iopub.status.idle":"2021-10-23T16:45:19.463418Z","shell.execute_reply.started":"2021-10-23T16:45:19.450757Z","shell.execute_reply":"2021-10-23T16:45:19.462509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"デバッグ用ファイル保存","metadata":{}},{"cell_type":"code","source":"# deepsort_out.to_csv(\"deepsort_out.csv\")\n# submission_deepsort.to_csv(\"sub_deepsort.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-10-23T16:45:21.311784Z","iopub.execute_input":"2021-10-23T16:45:21.312126Z","iopub.status.idle":"2021-10-23T16:45:21.486399Z","shell.execute_reply.started":"2021-10-23T16:45:21.312093Z","shell.execute_reply":"2021-10-23T16:45:21.485539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check Submission & Save\nFinally we will create a submission file and check that it passes the submission requirements.\nThe steps are:\n1. Drop the `label` and replace with `label_deepsort` predictions.\n2. Remove any duplicate labels within a single video/frame. This is required to meet the submission requirements.\n3. Save the results.","metadata":{}},{"cell_type":"code","source":"ss = pd.read_csv('../input/nfl-health-and-safety-helmet-assignment/sample_submission.csv')\n# Final Checks\nsubmission_deepsort['label_deepsort'] = submission_deepsort['label_deepsort'] \\\n    .fillna(submission_deepsort['label'])\nsubmission_deepsort = submission_deepsort.drop('label', axis=1) \\\n    .rename(columns={'label_deepsort':'label'})[ss.columns]\n# Drop duplicate labels\nsubmission_deepsort = submission_deepsort.loc[\n    ~submission_deepsort[['video_frame','label']].duplicated()]\ncheck_submission(submission_deepsort)\n\nsubmission_deepsort.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T14:50:59.264698Z","iopub.execute_input":"2021-10-23T14:50:59.265041Z","iopub.status.idle":"2021-10-23T14:50:59.366216Z","shell.execute_reply.started":"2021-10-23T14:50:59.265011Z","shell.execute_reply":"2021-10-23T14:50:59.365414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# なんかうごかねえ軍団\n","metadata":{}}]}